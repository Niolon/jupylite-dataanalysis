{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Pandas Exercise\n",
    "\n",
    "First import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": [
    "# Import pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "\n",
    "For this exercise, you will retrace another [post from the DataColada blog](https://datacolada.org/110), that looks at [this publication](https://journals.sagepub.com/doi/abs/10.1177/0956797615575277).\n",
    "\n",
    "After being asked to express their opinion on a local campus issue at Harvard University, students were then tasked with arguing for or against their own opinion. The hypothesis was that this would increase the desire for cleansing products.\n",
    "\n",
    "### Task 1: Import Data\n",
    "- **Loading the data into pandas**. For this experiment, you will load a CSV file containing responses from the survey. This data includes demographic information and participants' ratings of cleansing products.\n",
    "- **Commands to use**: Use `pd.read_csv()` to load your dataset into a pandas DataFrame. The file is located in `../Data/exercise/Gino_Kouchaki_Galinsky_Study_4_Data.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "\n",
    "### Task 2: Preliminary Data Inspection\n",
    "- **Understand the structure**: Examine the first few rows to get an idea of the available data. Find the tables with the aggregated data: `av_products_clean` (average rating of cleansing products) and `condition`, where pro-attitudinal people agreeing with the choice they were making\n",
    "- **Commands to use**: Use `df.columns` to look at the available columns, as well as `df.head()` and `df.describe().T`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Task 3 Calculating the p-value for the original hypothesis\n",
    " - **Reproduce the originally reported significance**: Calculate the difference of averages in the desire for cleansing products between the group that did or did not argue against their conviction, as well as the p-value.\n",
    " - **Commands to use**: conditional selection, `ttest_ind` from `scipy.stats`, as well as mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "after:# Conducting two-sample ttest"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "# Conducting two-sample ttest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": [
    "# Use 'loc' with conditions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Task 4: Finding the suspect values\n",
    "- **Find the suspect values within the dataset**: Assess how students have responded to the 'yearSchool' question (*What year are you in your university?*), can you spot the answer that does not make sense (*try looking at the blog*). How long are the strings?\n",
    "- **Commands to use**: `df['yearSchool'].unique()`, and `df['yearSchool'].value_counts()` to display the first few rows and analyze the responses in the 'yearSchool' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "\n",
    "### Task 5: Data Cleaning\n",
    "- **Normalize the 'yearSchool' entries**: Remove leading/trailing spaces, convert to lower case and create a binary column to flag responses that anomalously say 'Harvard'\u2014this is suspected to be a data tampering indicator.\n",
    "- **Commands to use**: Utilize the `str.strip()` attribute of a `pd.Series`, and the `str.lower()` attribute of a series to mark the suspect data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "\n",
    "### Task 6: Descriptive Statistics\n",
    "- **Basic Statistics**: Calculate the mean and standard deviation of the ratings for cleansing products for each survey condition.\n",
    "- **Commands to use**: Apply `df.groupby()`, `df.mean()`, and `df.std()` to group the data by condition and calculate these statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "after:# Group the data by condition and calculate the statistics"
   },
   "outputs": [],
   "source": [
    "df['argued_conviction'] = df['condition'] == 'ProAttitudinal'\n",
    "# Group the data by condition and calculate the statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "\n",
    "### Task 7: Visualization\n",
    "- **Plot the average ratings of cleansing products**: Distinguish between 'Harvard' and non-'Harvard' responses, to visualize potential impacts of the suspected tampered data.\n",
    "- **Commands to use**: Configure `plt.subplots()`, `ax.hist()`, and `plt.show()` to create histogram plots for the different categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": [
    "# Import matplotlib and Numpy\n",
    "\n",
    "# Create a figure and subplots\n",
    "\n",
    "# Plot the data\n",
    "\n",
    "# Show the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "\n",
    "### Task 8: Statistical Testing\n",
    "- **Conduct a t-test**: To confirm the authors' hypothesis that arguing against one\u2019s own side increases the desire for cleansing products\u2014and to check if the 'Harvard' data points influence this result.\n",
    "- **Commands to use**: Implement `scipy.stats.ttest_ind()` to perform the independent t-tests between groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": [
    "# Perform the independent t-tests between groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "remove_code": "non-comments"
   },
   "outputs": [],
   "source": [
    "# Perform the independent t-tests between groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}